{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b04b17cfbd0cd8b33d4effd80cf79090",
     "grade": false,
     "grade_id": "cell-c793b2b7fc5465d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Deadline:</b> March 23, 2022 (Wednesday) 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 2. Recommender system\n",
    "\n",
    "In this exercise, your task is to design a recommender system.\n",
    "\n",
    "## Learning goals:\n",
    "* Practise tuning a neural network model by using different regularization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tools\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97f36f0a997d795b2db131168549818c",
     "grade": true,
     "grade_id": "cell-281020e1f967884d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True\n",
    "\n",
    "import tools, warnings\n",
    "warnings.showwarning = tools.customwarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is ../data\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dc2c53928c3ad25702c9ac906bc6ac3",
     "grade": false,
     "grade_id": "cell-799c694caf47e754",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59060d908a6d0040774a9a7c24a2b78a",
     "grade": false,
     "grade_id": "cell-93b1b51f03178ceb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Ratings dataset\n",
    "\n",
    "We will train the recommender system on the dataset in which element consists of three values:\n",
    "* `user_id` - id of the user (the smallest user id is 1)\n",
    "* `item_id` - id of the movie (the smallest item id is 1)\n",
    "* `rating` - rating given by the user to the item (ratings are integer numbers between 1 and 5.\n",
    "\n",
    "The recommender system need to predict the rating for any given pair of `user_id` and `item_id`.\n",
    "\n",
    "We measure the quality of the predicted ratings using the mean-squared error (MSE) loss:\n",
    "$$\n",
    "  \\frac{1}{N}\\sum_{i=1}^N (r_i - \\hat{r}_i)^2\n",
    "$$\n",
    "where $r_i$ is a real rating and $\\hat{r}_i$ is a predicted one.\n",
    "\n",
    "Note: The predicted rating $\\hat{r}_i$ does not have to be an integer number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49c9bb6f71c5bebac88f572ebc5fdf21",
     "grade": false,
     "grade_id": "cell-fb7ca3b718244670",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "trainset = data.RatingsData(root=data_dir, train=True)\n",
    "testset = data.RatingsData(root=data_dir, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa25e5e6256ec9dcb5dffe5b20d88f87",
     "grade": false,
     "grade_id": "cell-35493e186fda7a43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id=1, item_id=1, rating=5\n"
     ]
    }
   ],
   "source": [
    "# Print one sample from the dataset\n",
    "x = trainset[0]\n",
    "print(f'user_id={x[0]}, item_id={x[1]}, rating={x[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6cab9939fbd855618ea15049c6584c91",
     "grade": false,
     "grade_id": "cell-40d7d3e85e395d42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Model\n",
    "\n",
    "You need to design a recommender system model with the API described in the cell below.\n",
    "\n",
    "Hints on the model architecture:\n",
    "* You need to use [torch.nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html?highlight=embedding#torch.nn.Embedding) layer to convert inputs `user_ids` and `item_ids` into reasonable representations. The idea of the embedding layer is that we want to represent similar users with values that are close to each other. The original representation as integers is not good for that. By using the embedding layer, we can learn such useful representations automatically.\n",
    "\n",
    "### Model tuning\n",
    "\n",
    "In this exercise, you need to tune the architecture of your model to achieve the best performance on the provided test set. You will notice that overfitting is a severe problem for this data: The model can easily overfit the training set producing poor accuracy on the out-of-training (test) data.\n",
    "\n",
    "You need to find an optimal combination of the hyperparameters, with some hyperparameters corresponding to the regularization techniques that we studied in the lecture.\n",
    "\n",
    "The hyperparameters that you are advised to consider:\n",
    "* Learning rate value and learning rate schedule (decresing the learning rate often has positive effect on the model performance)\n",
    "* Number of training epochs\n",
    "* Network size\n",
    "* Weight decay\n",
    "* Early stopping\n",
    "* Dropout\n",
    "* Increase amount of data:\n",
    "  * Data augmentation\n",
    "  * Injecting noise\n",
    "\n",
    "You can tune the hyperparameters by, for example, grid search, random search or manual tuning. In that case, you can use `architecture` argument to specify the hyperparameters that define the architecture of your network. After you have tuned the hyperparameters, set the default value of this argument to the optimal set of the hyparameters so that the best architecture is used in the accuracy tests.\n",
    "\n",
    "Note:\n",
    "* The number of points that you will get from this exercise depends on the MSE loss on the test set:\n",
    "  * below 1.00: 1 point\n",
    "  * below 0.95: 2 points\n",
    "  * below 0.92: 3 points\n",
    "  * below 0.90: 4 points\n",
    "  * below 0.89: 5 points\n",
    "  * below 0.88: 6 points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e5876624dba2e059f4aea1c65d27dfa",
     "grade": false,
     "grade_id": "cell-c3cffbe259a08d4d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class RecommenderSystem(nn.Module):\n",
    "    def __init__(self, n_users, n_items,\n",
    "                 architecture={'nof_layers': 3,\n",
    "                               'nodes': [372, 364],\n",
    "                               'dropout_rates': [0.021, 0.174, 0.36]}\n",
    "                                    # If you want to tune the hyperparameters automatically (e.g. using random\n",
    "                                    # search), use this argument to specify the hyperparameters that define the\n",
    "                                    # architecture of your network. After you have tuned the hyperparameters,\n",
    "                                    # set the default value of this argument to the optimal set of the hyparameters\n",
    "                                    # so that the best architecture is used in the accuracy tests.\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_users: Number of users.\n",
    "          n_items: Number of items.\n",
    "        \"\"\"\n",
    "        super(RecommenderSystem, self).__init__()\n",
    "        #self.n_users = n_users\n",
    "        #self.n_items = n_items\n",
    "        self.n_emb = 1000\n",
    "        \n",
    "        self.users_e = nn.Embedding(n_users, self.n_emb)\n",
    "        self.items_e = nn.Embedding(n_items, self.n_emb)\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if architecture is None:\n",
    "          self.layers.append(nn.Sequential(\n",
    "                        nn.Dropout(p = 0.1),\n",
    "                        nn.Linear(self.n_emb*2 ,1),\n",
    "                        nn.ReLU()))\n",
    "\n",
    "        if architecture is not None:\n",
    "          dropout_rates = architecture[\"dropout_rates\"]\n",
    "          nodes = architecture[\"nodes\"]\n",
    "          nof_layers = architecture[\"nof_layers\"]\n",
    "          dropout_rates = architecture[\"dropout_rates\"]\n",
    "          self.layers.append(nn.Sequential(\n",
    "                              nn.Dropout(p = dropout_rates[0]),\n",
    "                              nn.Linear(self.n_emb*2,nodes[0]),\n",
    "                              nn.ReLU()))\n",
    "          if nof_layers > 2:\n",
    "              for i in range(nof_layers-2):\n",
    "                  self.layers.append(nn.Sequential(\n",
    "                                      nn.Dropout(p = dropout_rates[i+1]),\n",
    "                                      nn.Linear(nodes[i],nodes[i+1]),\n",
    "                                      nn.ReLU()))\n",
    "          self.layers.append(nn.Sequential(\n",
    "                              nn.Dropout(p = dropout_rates[len(dropout_rates)-1]),\n",
    "                              nn.Linear(nodes[len(nodes)-1],1),\n",
    "                              nn.ReLU()))\n",
    "        \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          user_ids of shape (batch_size): User ids (starting from 1).\n",
    "          item_ids of shape (batch_size): Item ids (starting from 1).\n",
    "        \n",
    "        Returns:\n",
    "          outputs of shape (batch_size): Predictions of ratings.\n",
    "        \"\"\"\n",
    "        corrected_user_ids = torch.tensor(list(map(lambda id: id - 1, user_ids)), dtype=torch.int32)\n",
    "        corrected_item_ids = torch.tensor(list(map(lambda id: id - 1, item_ids)), dtype=torch.int32)\n",
    "        features = torch.cat([self.users_e(corrected_user_ids), self.items_e(corrected_item_ids)], dim=1)\n",
    "        x = features\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        res = x\n",
    "        return torch.reshape(res, (-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01bb09f330da9db46e6c8215cba93908",
     "grade": false,
     "grade_id": "cell-4963b96623072e67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can test the shapes of the model outputs using the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66e06523fac3af0ef33791d1f4b8b3d8",
     "grade": false,
     "grade_id": "cell-c6083c824af45d0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_RecommenderSystem_shapes():\n",
    "    n_users, n_items = 100, 1000\n",
    "    model = RecommenderSystem(n_users, n_items)\n",
    "    batch_size = 10\n",
    "    user_ids = torch.arange(1, batch_size+1)\n",
    "    item_ids = torch.arange(1, batch_size+1)\n",
    "    output = model(user_ids, item_ids)\n",
    "    print(output.shape)\n",
    "    assert output.shape == torch.Size([batch_size]), \"Wrong output shape.\"\n",
    "    print('Success')\n",
    "\n",
    "test_RecommenderSystem_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "450b5cbba95ea6ca97ff7d0c086abcc2",
     "grade": true,
     "grade_id": "cell-77bda8eb73762ef9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84fa4c2396a00177cefc9ae035b5ad1c",
     "grade": false,
     "grade_id": "cell-ba8b7cb0e60e0809",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Train the model\n",
    "\n",
    "You need to train a recommender system using **only the training data.** Please use the test set to select the best model: the model that generalizes best to out-of-training data.\n",
    "\n",
    "**IMPORTANT**:\n",
    "* During testing, the predictions are produced by `predictions = model(user_ids, item_ids)` with the `user_ids` and `item_ids` loaded from `RatingsData`.\n",
    "* There is a size limit of 30Mb for saved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, testloader, criterion):\n",
    "    model.eval()\n",
    "    evals = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for user_ids, item_ids, ratings in testloader:\n",
    "            user_ids, item_ids, ratings = user_ids.to(device), item_ids.to(device), ratings.to(device).type(torch.float32)\n",
    "            output = model(user_ids, item_ids).to(device)\n",
    "            #_, predicted = torch.max(outputs.data, 1)\n",
    "            evals += 1\n",
    "            total += criterion(output, ratings).to(device).item()\n",
    "    return total / evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9de82b03bc4514fc2e9c8e71fe0eab6f",
     "grade": false,
     "grade_id": "cell-d149dfc0245469b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "# IMPORTANT: the default value of the architecture argument should define your best model.\n",
    "model = RecommenderSystem(trainset.n_users, trainset.n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "  import time\n",
    "  from ray import tune\n",
    "  from ray.tune import JupyterNotebookReporter\n",
    "  from ray.tune.schedulers import ASHAScheduler\n",
    "  from ray.tune.stopper import TrialPlateauStopper\n",
    "  gpu_count = 0\n",
    "  if torch.cuda.is_available():\n",
    "      gpu_count = torch.cuda.device_count()\n",
    "      if gpu_count > 1:\n",
    "          model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ae611f86dc42c930a1421847d3310e8",
     "grade": false,
     "grade_id": "cell-d821843867334aed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 17:30:57,152\tINFO trial_runner.py:803 -- starting training_loop_eff83_00000\n",
      "2022-04-29 17:30:59,150\tWARNING util.py:171 -- The `start_trial` operation took 1.998 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m C:\\Users\\Christian Segercrant\\AppData\\Local\\Programs\\Python\\Python39\\python.exe: can't find '__main__' module in 'C:\\\\Users\\\\Christian'\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-04-29 17:31:00,097\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\Christian Segercrant\\AppData\\Local\\Programs\\Python\\Python39\\python.exe\" C:\\Users\\Christian Segercrant\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=65337 --object-store-name=tcp://127.0.0.1:59051 --raylet-name=tcp://127.0.0.1:57726 --redis-address=None --storage=None --temp-dir=C:\\Users\\CHRIST~1\\AppData\\Local\\Temp\\ray --metrics-agent-port=61681 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:57584 --redis-password=5241590000000000 --startup-token=14 --runtime-env-hash=2105003074\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-04-29 17:31:00,450 E 20928 3752] (raylet.exe) worker_pool.cc:518: Some workers of the worker process(15736) have not registered within the timeout. The process is dead, probably it crashed during start.\n",
      "2022-04-29 17:31:04,205\tWARNING tune.py:650 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-04-29 17:31:29,159 E 20928 3752] (raylet.exe) worker_pool.cc:518: Some workers of the worker process(23468) have not registered within the timeout. The process is dead, probably it crashed during start.\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m C:\\Users\\Christian Segercrant\\AppData\\Local\\Programs\\Python\\Python39\\python.exe: can't find '__main__' module in 'C:\\\\Users\\\\Christian'\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-04-29 17:31:30,090\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\Christian Segercrant\\AppData\\Local\\Programs\\Python\\Python39\\python.exe\" C:\\Users\\Christian Segercrant\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=65337 --object-store-name=tcp://127.0.0.1:59051 --raylet-name=tcp://127.0.0.1:57726 --redis-address=None --storage=None --temp-dir=C:\\Users\\CHRIST~1\\AppData\\Local\\Temp\\ray --metrics-agent-port=61681 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:57584 --redis-password=5241590000000000 --startup-token=15 --runtime-env-hash=2105003074\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-04-29 17:31:59,178 E 20928 3752] (raylet.exe) worker_pool.cc:518: Some workers of the worker process(4812) have not registered within the timeout. The process is dead, probably it crashed during start.\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m C:\\Users\\Christian Segercrant\\AppData\\Local\\Programs\\Python\\Python39\\python.exe: can't find '__main__' module in 'C:\\\\Users\\\\Christian'\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-04-29 17:32:00,035\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\Christian Segercrant\\AppData\\Local\\Programs\\Python\\Python39\\python.exe\" C:\\Users\\Christian Segercrant\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=65337 --object-store-name=tcp://127.0.0.1:59051 --raylet-name=tcp://127.0.0.1:57726 --redis-address=None --storage=None --temp-dir=C:\\Users\\CHRIST~1\\AppData\\Local\\Temp\\ray --metrics-agent-port=61681 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:57584 --redis-password=5241590000000000 --startup-token=16 --runtime-env-hash=2105003074\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHRIST~1\\AppData\\Local\\Temp/ipykernel_18320/3346294539.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m#hyperopt_search = HyperOptSearch(config, metric=\"validation_error\", mode=\"min\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     result  = tune.run(run_or_experiment  = training_loop,\n\u001b[0m\u001b[0;32m     69\u001b[0m                        \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                        \u001b[1;31m#metric = \"validation_error\",\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\tune\\tune.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, queue_trials, loggers, _remote)\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m             \u001b[0m_report_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m     \u001b[0mtune_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtune_start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\tune\\tune.py\u001b[0m in \u001b[0;36m_report_progress\u001b[1;34m(runner, reporter, done)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0msched_debug_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheduler_alg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mexecutor_debug_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mreporter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msched_debug_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_debug_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\tune\\progress_reporter.py\u001b[0m in \u001b[0;36mreport\u001b[1;34m(self, trials, done, *sys_info)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTrial\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msys_info\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[0moverwrite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overwrite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m         progress_str = self._progress_str(\n\u001b[0m\u001b[0;32m    471\u001b[0m             \u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msys_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"html\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"<br>\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\tune\\progress_reporter.py\u001b[0m in \u001b[0;36m_progress_str\u001b[1;34m(self, trials, done, fmt, delim, *sys_info)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[0mmax_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_error_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[0mcurrent_best_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_best_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcurrent_best_trial\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             messages.append(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\tune\\progress_reporter.py\u001b[0m in \u001b[0;36m_current_best_trial\u001b[1;34m(self, trials)\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0mbest_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\tune\\trial.py\u001b[0m in \u001b[0;36mlast_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mTRIAL_ID\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_default_result_or_future\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_result_or_future\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRIAL_ID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\tune\\trial.py\u001b[0m in \u001b[0;36m_get_default_result_or_future\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    404\u001b[0m         ):\n\u001b[0;32m    405\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_result_or_future\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_result_or_future\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mRayActorError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# error during initialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_result_or_future\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\_private\\client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"init\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\worker.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(object_refs, timeout)\u001b[0m\n\u001b[0;32m   1801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1802\u001b[0m         \u001b[1;31m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1803\u001b[1;33m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebugger_breakpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1804\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1805\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRayError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ray\\worker.py\u001b[0m in \u001b[0;36mget_objects\u001b[1;34m(self, object_refs, timeout)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0mtimeout_ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         data_metadata_pairs = self.core_worker.get_objects(\n\u001b[0m\u001b[0;32m    363\u001b[0m             \u001b[0mobject_refs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         )\n",
      "\u001b[1;32mpython\\ray\\_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpython\\ray\\_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Implement the training loop in this cell\n",
    "if not skip_training:\n",
    "\n",
    "\n",
    "    def training_loop(hyperparameters, tune_mode = True):\n",
    "        model = RecommenderSystem(trainset.n_users,\n",
    "                                  trainset.n_items, \n",
    "                                  {\"nof_layers\": hyperparameters[\"nof_layers\"],\n",
    "                                   \"nodes\": hyperparameters[\"nodes\"],\n",
    "                                   \"dropout_rates\": hyperparameters[\"dropout_rates\"]})\n",
    "        #Training\n",
    "        trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                                  batch_size=hyperparameters[\"batch_size\"],\n",
    "                                                  shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(testset)\n",
    "        \n",
    "        params = list(model.parameters())\n",
    "        optimizer = torch.optim.Adam(params, lr=hyperparameters[\"lr\"], weight_decay = hyperparameters[\"weight_decay\"])\n",
    "        criterion = nn.MSELoss()\n",
    "        for i in range(hyperparameters[\"epochs\"]):\n",
    "            model.train()\n",
    "            for user_ids, item_ids, ratings in trainloader:\n",
    "                user_ids, item_ids, ratings = user_ids.to(device), item_ids.to(device), ratings.to(device).type(torch.float32)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(user_ids, item_ids).to(device)\n",
    "                loss = criterion(output, ratings)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            training_error = loss.item()\n",
    "            test_error = compute_accuracy(model, testloader, criterion)\n",
    "            if tune_mode:\n",
    "                tune.report(training_error = training_error, validation_error = test_error)\n",
    "                torch.save(model.state_dict(), \"./model.pth\")\n",
    "            else:\n",
    "                print(f\"During epoch {i+1} training error = {training_error} and validation error = {test_error}\")\n",
    "        #torch.save(model.state_dict(), \"./model.pth\")\n",
    "    #Hyperparameters\n",
    "    config = {\n",
    "    \"lr\": 0.001,#tune.qloguniform(1e-5, 2e-2, 1e-6),\n",
    "    \"epochs\": 14,\n",
    "    \"batch_size\": 159,#tune.randint(100,500),\n",
    "    \"weight_decay\": 0.004,#tune.quniform(0, 0.10, 0.001),\n",
    "    \"nof_layers\": 3,#tune.randint(2,7), #min 2 layers by default\n",
    "    \"nodes\": [372, 364],#tune.sample_from(lambda spec:[np.random.randint(1,100) for i in range(spec.config.nof_layers-1)]),\n",
    "    \"dropout_rates\": [0.021, 0.174, 0.36]}#tune.sample_from(lambda spec:[np.round(np.random.uniform(0, 0.5),decimals=3) for i in range(spec.config.nof_layers)])}\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"validation_error\",\n",
    "        mode=\"min\",\n",
    "        grace_period = 3)\n",
    "    \n",
    "    reporter = JupyterNotebookReporter(\n",
    "        metric_columns=[\"training_error\", \"validation_error\", \"training_iteration\"],\n",
    "        overwrite = True,\n",
    "        print_intermediate_tables = True,\n",
    "        sort_by_metric = True,\n",
    "        metric = \"validation_error\",\n",
    "        mode = \"min\")\n",
    "    \n",
    "    stopper = TrialPlateauStopper(metric = 'validation_error',\n",
    "                                  std = 0.01,\n",
    "                                  num_results= 3,\n",
    "                                  metric_threshold = 1.1,\n",
    "                                  mode = 'max')\n",
    "    \n",
    "    #hyperopt_search = HyperOptSearch(config, metric=\"validation_error\", mode=\"min\")\n",
    "    \n",
    "    result  = tune.run(run_or_experiment  = training_loop,\n",
    "                       config = config,\n",
    "                       #metric = \"validation_error\",\n",
    "                       #mode = \"min\",\n",
    "                       num_samples=10,\n",
    "                       resources_per_trial = {\"gpu\": gpu_count/2, \"cpu\": (torch.get_num_threads()/2)},\n",
    "                       verbose = 1,\n",
    "                       scheduler = scheduler,\n",
    "                       progress_reporter=reporter,\n",
    "                       stop=stopper)\n",
    "                       \n",
    "    best_trial = result.get_best_trial(\"validation_error\", \"min\", \"last\")\n",
    "    if(best_trial):\n",
    "        print(\"Best trial config: {}\".format(best_trial.config))\n",
    "        print(\"Best trial final validation error: {}\".format(\n",
    "            best_trial.last_result[\"validation_error\"]))\n",
    "    else:\n",
    "        print(\"No best trial\")\n",
    "        \n",
    "    #visualization\n",
    "    dfs = result.trial_dataframes\n",
    "\n",
    "    # Plot by epoch\n",
    "    ax = None  # This plots everything on the same plot\n",
    "    for d in dfs.values():\n",
    "        ax = d.validation_error.plot(ax=ax, legend=False)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Validation error')\n",
    "    ax.set_ylim(0.5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'lr': 8e-05, 'epochs': 5, 'batch_size': 336, 'weight_decay': 0.049, 'nof_layers': 6, 'nodes': [405, 347, 425, 396, 350], 'dropout_rates': [0.046, 0.017, 0.128, 0.01, 0.234, 0.177]} # 0.9414899543032127\n",
    "#{'lr': 7.0e-05, 'epochs': 9, 'batch_size': 159, 'weight_decay': 0.004, 'nof_layers': 3, 'nodes': [372, 364], 'dropout_rates': [0.021, 0.174, 0.36]} #0.9162588702653133\n",
    "#{'lr': 0.001, 'epochs': 15, 'batch_size': 100, 'weight_decay': 0.001, 'nof_layers': 2, 'nodes': [10], 'dropout_rates': [0.02, 0.02]}# 0.8571209062045327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "  df = result.results_df\n",
    "  logdir = result.get_best_logdir(\"validation_error\", mode=\"min\")\n",
    "  state_dict = torch.load(os.path.join(logdir, \"model.pth\"))\n",
    "\n",
    "  model = RecommenderSystem(trainset.n_users,\n",
    "                            trainset.n_items,\n",
    "                            architecture={'nof_layers': 3,\n",
    "                                          'nodes': [372, 364],\n",
    "                                          'dropout_rates': [0.021, 0.174, 0.36]})\n",
    "  model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "# Set confirm=False if you do not want to be asked for confirmation before saving.\n",
    "if not skip_training:\n",
    "    tools.save_model(model, 'recsys.pth', confirm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13f9cd9f77491dbdc099d1f0abb4ddbd",
     "grade": false,
     "grade_id": "cell-f1407ea48ef44720",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from recsys.pth.\n"
     ]
    }
   ],
   "source": [
    "# This cell loads your best model\n",
    "if skip_training:\n",
    "    model = RecommenderSystem(trainset.n_users, trainset.n_items)\n",
    "    tools.load_model(model, 'recsys.pth', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "  testloader = torch.utils.data.DataLoader(testset)\n",
    "  criterion = nn.MSELoss()\n",
    "  compute_accuracy(model, testloader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3a0c9a862742764c451006091c5295f",
     "grade": false,
     "grade_id": "cell-0968d93ce893a867",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The next cell tests the accuracy of your best model. It is enough to submit .pth files.\n",
    "\n",
    "**IMPORTANT**:\n",
    "* During testing, the predictions are produced by `predictions = model(user_ids, item_ids)` with the `user_ids` and `item_ids` loaded from `RatingsData`.\n",
    "* There is a size limit of 30Mb for saved models. Please make sure that your model loads in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5da1ca794d9decc9969a31342685666",
     "grade": true,
     "grade_id": "cell-bffe8fbb471081d9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests the accuracy of your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6424893302c13e465c2c75bbe70f8735",
     "grade": true,
     "grade_id": "cell-cd5e14d4b944f427",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c30f9763e61f52dedcc999c69901c79",
     "grade": true,
     "grade_id": "cell-d6d18ec22f375541",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bb64cc670252d78e6d0610fc87f818d",
     "grade": true,
     "grade_id": "cell-2a7cbd80cefdfc28",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "655de66b979f1ac0bc9009ef71201bee",
     "grade": true,
     "grade_id": "cell-583d64dae36d06ae",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3df236f1b1d600d0ef716148cce58c46",
     "grade": true,
     "grade_id": "cell-545fe9918fc5b54a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "845675607fd47b1ece1e7c5288e11561",
     "grade": true,
     "grade_id": "cell-a890dc0ffcb07f46",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for grading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
